import logging
import os
from typing import List, Tuple
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain.docstore.document import Document
from dotenv import load_dotenv

# ============ LLM & NER ============
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

load_dotenv()

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)

EMBEDDING_MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)

def load_vectorstore(
    persist_dir: str = "./chroma_data",
    collection_name: str = "job_postings"
) -> Chroma:
    logger.info("Loading existing vector store")
    vectorstore = Chroma(
        embedding_function=embedding_model,
        collection_name=collection_name,
        persist_directory=persist_dir
    )
    logger.info("Vector store loaded successfully")
    return vectorstore

# 1) ì‚¬ìš©ì ì¿¼ë¦¬ NER (LLMChain)
def setup_query_ner_chain() -> LLMChain:
    openai_api_key = os.environ.get("OPENAI_API_KEY")
    if not openai_api_key:
        raise ValueError("OPENAI_API_KEY is not set in .env")

    llm = ChatOpenAI(
        openai_api_key=openai_api_key,
        model_name="gpt-4o-mini",
        temperature=0.0
    )
    prompt = PromptTemplate(
        input_variables=["query"],
        template=(
            "ì‚¬ìš©ì ì…ë ¥: {query}\n\n"
            "ìœ„ ë¬¸ì¥ì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” ì§ë¬´, ì§€ì—­, ì—°ë ¹ëŒ€, ê¸°íƒ€ ì¤‘ìš”í•œ ìš”ì†Œë¥¼ JSONìœ¼ë¡œ ì¶”ì¶œí•´ì¤˜.\n"
            "ì˜ˆ: {\"ì§ë¬´\":\"ê°„í˜¸\", \"ì§€ì—­\":\"ì„œìš¸\", \"ì—°ë ¹ëŒ€\":\"50ëŒ€\"} ë“±\n"
        )
    )
    chain = LLMChain(llm=llm, prompt=prompt)
    return chain

# 2) ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ (LLMChain)
def setup_summary_chain() -> LLMChain:
    openai_api_key = os.environ.get("OPENAI_API_KEY")
    llm = ChatOpenAI(
        openai_api_key=openai_api_key,
        model_name="gpt-4o-mini",
        temperature=0.5
    )
    # ê°„ë‹¨í•œ ìš”ì•½ í”„ë¡¬í”„íŠ¸
    summary_prompt = PromptTemplate(
        input_variables=["query", "raw_docs"],
        template=(
            "ì‚¬ìš©ì ê²€ìƒ‰ì–´: {query}\n\n"
            "ì•„ë˜ ì±„ìš©ê³µê³  ëª©ë¡ì— ëŒ€í•´, í•µì‹¬ ì •ë³´ì™€ ì‚¬ìš©ì ì˜ë„ì— ë§ëŠ”ì§€ ë¶„ì„í•˜ì—¬ ê°„ëµíˆ ìš”ì•½í•´ì¤˜.\n\n"
            "{raw_docs}\n\n"
            "ì‘ë‹µ ì˜ˆì‹œ:\n"
            "- ì´ {N}ê°œ ê³µê³ ê°€ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
            "- ì²« ë²ˆì§¸ ê³µê³ : ~ (ìš”ì•½)\n"
        )
    )
    chain = LLMChain(llm=llm, prompt=summary_prompt)
    return chain

def main():
    vectorstore = load_vectorstore()
    query_ner_chain = setup_query_ner_chain()
    summary_chain = setup_summary_chain()

    # ì‚¬ìš©ì ê²€ìƒ‰ ì…ë ¥
    query = input("\nğŸ” ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    if not query:
        print("ê²€ìƒ‰ì–´ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return

    # 1) ì‚¬ìš©ì ì¿¼ë¦¬ NER
    ner_result_str = query_ner_chain.run({"query": query})
    import json
    try:
        ner_dict = json.loads(ner_result_str)
    except json.JSONDecodeError:
        ner_dict = {}

    # 2) NER ê¸°ë°˜ ì¿¼ë¦¬ í™•ì¥
    query_terms = []
    for k, v in ner_dict.items():
        if isinstance(v, str) and v:
            query_terms.append(v)
    # ì›ë³¸ ì¿¼ë¦¬ë„ ì¶”ê°€
    query_terms.append(query)
    final_query = " ".join(query_terms)

    # 3) ë²¡í„° ê²€ìƒ‰ (with score)
    #    ìœ ì‚¬ë„ ì ìˆ˜ë„ í•¨ê»˜ ë°›ì•„ì„œ threshold í•„í„° ê°€ëŠ¥
    results_with_score: List[Tuple[Document, float]] = vectorstore.similarity_search_with_score(final_query, k=5)
    if not results_with_score:
        print("ê²€ìƒ‰ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 4) ê²°ê³¼ ë¬¸ì„œ í‘œì‹œ
    print("\n==== ğŸ“Œ ê²€ìƒ‰ëœ ì±„ìš©ê³µê³  ====")
    doc_texts = []
    for i, (doc, score) in enumerate(results_with_score):
        md = doc.metadata
        snippet = (
            f"[{i+1}] ì œëª©: {md.get('ì±„ìš©ì œëª©')} / "
            f"íšŒì‚¬: {md.get('íšŒì‚¬ëª…')} / "
            f"ê·¼ë¬´ì§€: {md.get('ê·¼ë¬´ì§€ì—­')} / "
            f"NER(ê³µê³ ): {md.get('NER', {})}"
            f"\nìœ ì‚¬ë„ ì ìˆ˜: {score}\n"
        )
        print(snippet)
        doc_texts.append(snippet)

    # 5) LLMì„ í†µí•œ ìš”ì•½
    joined_docs = "\n".join(doc_texts)
    summary = summary_chain.run({"query": query, "raw_docs": joined_docs})
    print("\n=== LLM ìš”ì•½ ===")
    print(summary)


if __name__ == "__main__":
    main()
